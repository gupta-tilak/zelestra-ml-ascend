{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed4c2bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒž SOLAR PANEL PERFORMANCE MODEL SELECTION\n",
      "==================================================\n",
      "ðŸ”§ Initializing model selector...\n",
      "ðŸš€ Starting complete pipeline...\n",
      "ðŸš€ STARTING COMPLETE SOLAR PANEL MODEL SELECTION PIPELINE\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š STEP 1: Data Loading and Preparation\n",
      "Loading raw data...\n",
      "Raw dataset shape: (20000, 17)\n",
      "Missing values in raw data:\n",
      "temperature           1001\n",
      "irradiance             987\n",
      "panel_age             1011\n",
      "maintenance_count     1027\n",
      "soiling_ratio         1010\n",
      "voltage                993\n",
      "current                977\n",
      "module_temperature     978\n",
      "cloud_coverage        1010\n",
      "error_code            5912\n",
      "installation_type     5028\n",
      "dtype: int64\n",
      "\n",
      "Step 1: Fixing data types...\n",
      "\n",
      "=== FIXING DATA TYPES FOR TRAINING DATA ===\n",
      "\n",
      "Processing humidity:\n",
      "Original dtype: object\n",
      "Non-numeric values found in humidity:\n",
      "humidity\n",
      "unknown    50\n",
      "error      40\n",
      "badval     37\n",
      "Name: count, dtype: int64\n",
      "Converted dtype: float64\n",
      "Missing values after conversion: 127\n",
      "Valid numeric values: 19873\n",
      "Min: 0.011\n",
      "Max: 99.995\n",
      "Mean: 50.066\n",
      "\n",
      "Processing wind_speed:\n",
      "Original dtype: object\n",
      "Non-numeric values found in wind_speed:\n",
      "wind_speed\n",
      "badval     42\n",
      "error      41\n",
      "unknown    36\n",
      "Name: count, dtype: int64\n",
      "Converted dtype: float64\n",
      "Missing values after conversion: 119\n",
      "Valid numeric values: 19881\n",
      "Min: 0.001\n",
      "Max: 14.999\n",
      "Mean: 7.413\n",
      "\n",
      "Processing pressure:\n",
      "Original dtype: object\n",
      "Non-numeric values found in pressure:\n",
      "pressure\n",
      "unknown    46\n",
      "error      45\n",
      "badval     44\n",
      "Name: count, dtype: int64\n",
      "Converted dtype: float64\n",
      "Missing values after conversion: 135\n",
      "Valid numeric values: 19865\n",
      "Min: 970.087\n",
      "Max: 1052.866\n",
      "Mean: 1012.981\n",
      "\n",
      "=== DATA TYPE VERIFICATION ===\n",
      "Data types after fixing:\n",
      "humidity: float64\n",
      "wind_speed: float64\n",
      "pressure: float64\n",
      "\n",
      "Step 2: Applying imputation pipeline...\n",
      "Dataset shape after imputation: (20000, 17)\n",
      "Remaining missing values after imputation: 0\n",
      "\n",
      "Step 3: Creating engineered features...\n",
      "Dataset shape after feature engineering: (20000, 31)\n",
      "\n",
      "Step 4: Dropping features: ['soiling_loss', 'temp_difference', 'installation_type_tracking', 'pressure', 'wind_cooling_effect', 'id', 'voltage', 'current', 'temperature', 'module_temperature', 'irradiance', 'wind_speed', 'panel_age', 'cloud_coverage', 'soiling_ratio', 'maintenance_count', 'humidity']\n",
      "Dropped features: ['soiling_loss', 'temp_difference', 'installation_type_tracking', 'pressure', 'wind_cooling_effect', 'id', 'voltage', 'current', 'temperature', 'module_temperature', 'irradiance', 'wind_speed', 'panel_age', 'cloud_coverage', 'soiling_ratio', 'maintenance_count', 'humidity']\n",
      "Dataset shape after dropping features: (20000, 14)\n",
      "Categorical columns: ['string_id', 'error_code', 'installation_type']\n",
      "Numerical columns: ['power_output', 'irradiance_normalized', 'temp_coefficient_effect', 'expected_irradiance_clean', 'irradiance_cloud_ratio', 'age_degradation_factor', 'maintenance_frequency', 'environmental_stress', 'effective_module_temp']\n",
      "Total features: 13\n",
      "\n",
      "ðŸ”§ STEP 2: Creating Preprocessing Pipeline\n",
      "Creating preprocessing pipeline...\n",
      "\n",
      "âœ‚ï¸ STEP 3: Train-Test Split\n",
      "Preparing train-test split...\n",
      "Training set shape: (16000, 12)\n",
      "Test set shape: (4000, 12)\n",
      "\n",
      "ðŸ¤– STEP 4: Base Model Evaluation\n",
      "Defining models...\n",
      "Evaluating base models...\n",
      "Training Linear Regression...\n",
      "  âœ“ Linear Regression completed - Test Custom Score: 89.2771\n",
      "Training Ridge...\n",
      "  âœ“ Ridge completed - Test Custom Score: 89.2772\n",
      "Training Lasso...\n",
      "  âœ“ Lasso completed - Test Custom Score: 85.7084\n",
      "Training ElasticNet...\n",
      "  âœ“ ElasticNet completed - Test Custom Score: 86.3594\n",
      "Training Decision Tree...\n",
      "  âœ“ Decision Tree completed - Test Custom Score: 84.7013\n",
      "Training Random Forest...\n",
      "  âœ“ Random Forest completed - Test Custom Score: 89.2470\n",
      "Training Extra Trees...\n",
      "  âœ“ Extra Trees completed - Test Custom Score: 89.2365\n",
      "Training Gradient Boosting...\n",
      "  âœ“ Gradient Boosting completed - Test Custom Score: 89.3570\n",
      "Training XGBoost...\n",
      "  âœ“ XGBoost completed - Test Custom Score: 89.0774\n",
      "Training LightGBM...\n",
      "  âœ“ LightGBM completed - Test Custom Score: 89.3617\n",
      "Training CatBoost...\n",
      "  âœ“ CatBoost completed - Test Custom Score: 89.3584\n",
      "Training KNN...\n",
      "  âœ“ KNN completed - Test Custom Score: 88.0437\n",
      "Training SVR...\n",
      "  âœ“ SVR completed - Test Custom Score: 89.2108\n",
      "\n",
      "âš™ï¸ STEP 5: Hyperparameter Tuning\n",
      "Performing hyperparameter tuning for top 5 models...\n",
      "Tuning LightGBM...\n",
      "  âœ“ LightGBM tuning completed\n",
      "Tuning Gradient Boosting...\n",
      "  âœ“ Gradient Boosting tuning completed\n",
      "Tuning Ridge...\n",
      "  âœ“ Ridge tuning completed\n",
      "\n",
      "ðŸ—ï¸ STEP 6: Stacking Model Creation\n",
      "\n",
      "Creating stacking regressor with top 2 tuned models...\n",
      "Selected base estimators for stacking (tuned only):\n",
      "  1. LightGBM_Tuned - Test Custom Score: 89.3640\n",
      "  2. Gradient Boosting_Tuned - Test Custom Score: 89.3474\n",
      "Base estimator names: ['lightgbm', 'gradient_boosting']\n",
      "\n",
      "Training Stacking_Linear...\n",
      "  âœ“ Stacking_Linear completed - Test Custom Score: 89.3705\n",
      "\n",
      "Training Stacking_Ridge...\n",
      "  âœ“ Stacking_Ridge completed - Test Custom Score: 89.3705\n",
      "\n",
      "Training Stacking_Lasso...\n",
      "  âœ“ Stacking_Lasso completed - Test Custom Score: 89.2478\n",
      "\n",
      "Training Stacking_ElasticNet...\n",
      "  âœ“ Stacking_ElasticNet completed - Test Custom Score: 89.3032\n",
      "\n",
      "Training Stacking_Random Forest...\n",
      "  âœ“ Stacking_Random Forest completed - Test Custom Score: 88.9038\n",
      "\n",
      "Best stacking model: Stacking_Linear\n",
      "Test Custom Score: 89.3705\n",
      "Test RMSE: 0.1063\n",
      "Test RÂ²: 0.4380\n",
      "Base estimators used:\n",
      "  - LightGBM_Tuned (Tuned): 89.3640\n",
      "  - Gradient Boosting_Tuned (Tuned): 89.3474\n",
      "\n",
      "ðŸŽ¯ STEP 7: Best Model Selection\n",
      "\n",
      "============================================================\n",
      "SELECTING BEST MODEL\n",
      "============================================================\n",
      "ðŸ† BEST MODEL SELECTED: Stacking_Linear\n",
      "   Test Custom Score: 89.3705\n",
      "   Test RMSE: 0.1063\n",
      "   Test RÂ²: 0.4380\n",
      "   Base Estimators: [{'name': 'LightGBM_Tuned', 'type': 'lightgbm', 'is_tuned': True, 'score': np.float64(89.36396583802751)}, {'name': 'Gradient Boosting_Tuned', 'type': 'gradient_boosting', 'is_tuned': True, 'score': np.float64(89.3473615541867)}]\n",
      "   Meta Regressor: Random Forest\n",
      "\n",
      "ðŸ“Š STEP 8: Results Summary\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š DATASET INFORMATION:\n",
      "   Original Shape: (20000, 17)\n",
      "   Final Shape: (20000, 14)\n",
      "   Features Dropped: 17\n",
      "   Categorical Features: 3\n",
      "   Numerical Features: 9\n",
      "\n",
      "ðŸ¤– MODEL PERFORMANCE SUMMARY:\n",
      "\n",
      "   Base Models (13 models):\n",
      "      1. LightGBM: 89.3617\n",
      "      2. CatBoost: 89.3584\n",
      "      3. Gradient Boosting: 89.3570\n",
      "\n",
      "   Tuned Models (3 models):\n",
      "      1. LightGBM_Tuned: 89.3640\n",
      "      2. Gradient Boosting_Tuned: 89.3474\n",
      "      3. Ridge_Tuned: 89.2771\n",
      "\n",
      "   Stacking Models (5 models):\n",
      "      1. Stacking_Linear: 89.3705\n",
      "      2. Stacking_Ridge: 89.3705\n",
      "      3. Stacking_ElasticNet: 89.3032\n",
      "      4. Stacking_Lasso: 89.2478\n",
      "      5. Stacking_Random Forest: 88.9038\n",
      "\n",
      "ðŸ† BEST OVERALL MODEL:\n",
      "   Model: Stacking_Linear\n",
      "   Test Custom Score: 89.3705\n",
      "   Test RMSE: 0.1063\n",
      "   Test RÂ²: 0.4380\n",
      "   Train Custom Score: 90.0229\n",
      "   Overfitting Gap: 0.6524\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ðŸ’¾ STEP 9: Saving Best Model\n",
      "âœ… Best model with complete pipeline saved to model/best_solar_model_complete.pkl\n",
      "   Model: Stacking_Linear\n",
      "   Score: 89.3705\n",
      "\n",
      "ðŸŽ‰ PIPELINE COMPLETED SUCCESSFULLY!\n",
      "ðŸ† Best Model: Stacking_Linear\n",
      "ðŸ“ˆ Final Test Score: 89.3705\n",
      "\n",
      "ðŸŽŠ FINAL RESULTS:\n",
      "   Best Model: Stacking_Linear\n",
      "   Best Score: 89.3705\n",
      "\n",
      "ðŸ“ USAGE EXAMPLES:\n",
      "   # Load new data and make predictions:\n",
      "   # new_data = pd.read_csv('new_data.csv')\n",
      "   # predictions = selector.predict(new_data)\n",
      "   \n",
      "   # Load saved model in new session:\n",
      "   # new_selector = SolarPanelModelSelector()\n",
      "   # new_selector.load_model('model/best_solar_model_complete.pkl')\n",
      "   # predictions = new_selector.predict(new_data)\n",
      "\n",
      "ðŸ”„ Testing model save/load functionality...\n",
      "âœ… Best model with complete pipeline saved to model/test_model.pkl\n",
      "   Model: Stacking_Linear\n",
      "   Score: 89.3705\n",
      "âœ… Model with complete pipeline loaded successfully\n",
      "   Model: Stacking_Linear\n",
      "   Score: 89.3705\n",
      "âœ… Model save/load test successful!\n",
      "   Loaded model: Stacking_Linear\n",
      "   Loaded score: 89.3705\n",
      "\n",
      "ðŸ EXECUTION COMPLETED!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "# Neural Network imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "from utils.imputation import ImputationPipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class ANNRegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Custom ANN Regressor wrapper that mimics scikit-learn interface\n",
    "    \"\"\"\n",
    "    def __init__(self, neurons=128, layers=3, dropout_rate=0.3, \n",
    "                 learning_rate=0.001, l1_reg=0.0, l2_reg=0.01,\n",
    "                 epochs=200, batch_size=32, validation_split=0.2,\n",
    "                 patience=20, verbose=0):\n",
    "        self.neurons = neurons\n",
    "        self.layers = layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_reg = l1_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.validation_split = validation_split\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.model_ = None\n",
    "        self.history_ = None\n",
    "        \n",
    "    def _build_model(self, input_dim):\n",
    "        \"\"\"Build the neural network model\"\"\"\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Input layer\n",
    "        model.add(Dense(self.neurons, \n",
    "                       input_dim=input_dim,\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=l1_l2(l1=self.l1_reg, l2=self.l2_reg)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(self.dropout_rate))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for i in range(self.layers - 1):\n",
    "            # Gradually decrease neurons in deeper layers\n",
    "            layer_neurons = max(self.neurons // (2 ** i), 32)\n",
    "            model.add(Dense(layer_neurons,\n",
    "                           activation='relu',\n",
    "                           kernel_regularizer=l1_l2(l1=self.l1_reg, l2=self.l2_reg)))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(self.dropout_rate))\n",
    "        \n",
    "        # Output layer\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        \n",
    "        # Compile model\n",
    "        optimizer = Adam(learning_rate=self.learning_rate)\n",
    "        model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def fit(self, X, y, **kwargs):\n",
    "        \"\"\"Fit the neural network\"\"\"\n",
    "        # Convert to numpy arrays if needed\n",
    "        if hasattr(X, 'values'):\n",
    "            X = X.values\n",
    "        if hasattr(y, 'values'):\n",
    "            y = y.values\n",
    "            \n",
    "        # Ensure y is 1D\n",
    "        if len(y.shape) > 1:\n",
    "            y = y.flatten()\n",
    "        \n",
    "        # Build model\n",
    "        self.model_ = self._build_model(X.shape[1])\n",
    "        \n",
    "        # Set up callbacks\n",
    "        callbacks = [\n",
    "            EarlyStopping(patience=self.patience, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(patience=self.patience//2, factor=0.5, min_lr=1e-6)\n",
    "        ]\n",
    "        \n",
    "        # Train model\n",
    "        self.history_ = self.model_.fit(\n",
    "            X, y,\n",
    "            epochs=self.epochs,\n",
    "            batch_size=self.batch_size,\n",
    "            validation_split=self.validation_split,\n",
    "            callbacks=callbacks,\n",
    "            verbose=self.verbose\n",
    "        )\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        if self.model_ is None:\n",
    "            raise ValueError(\"Model must be fitted before making predictions\")\n",
    "            \n",
    "        # Convert to numpy array if needed\n",
    "        if hasattr(X, 'values'):\n",
    "            X = X.values\n",
    "            \n",
    "        predictions = self.model_.predict(X, verbose=0)\n",
    "        return predictions.flatten()\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\"Get parameters for this estimator\"\"\"\n",
    "        return {\n",
    "            'neurons': self.neurons,\n",
    "            'layers': self.layers,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "            'learning_rate': self.learning_rate,\n",
    "            'l1_reg': self.l1_reg,\n",
    "            'l2_reg': self.l2_reg,\n",
    "            'epochs': self.epochs,\n",
    "            'batch_size': self.batch_size,\n",
    "            'validation_split': self.validation_split,\n",
    "            'patience': self.patience,\n",
    "            'verbose': self.verbose\n",
    "        }\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        \"\"\"Set parameters for this estimator\"\"\"\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "        return self\n",
    "\n",
    "class SolarPanelModelSelector:\n",
    "    def __init__(self, data_path='dataset/train.csv', test_size=0.2, random_state=42, features_to_drop=None):\n",
    "        \"\"\"\n",
    "        Initialize the model selector with data loading and basic setup\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        self.best_model = None\n",
    "        self.preprocessor = None\n",
    "        self.imputer = None\n",
    "        self.features_to_drop = features_to_drop or []\n",
    "        \n",
    "        # Stacking-specific attributes\n",
    "        self.stacking_results = {}\n",
    "        self.best_stacking_model = None\n",
    "        \n",
    "    def fix_data_types(self, df, dataset_name):\n",
    "        \"\"\"Fix data type inconsistencies for specific columns\"\"\"\n",
    "        df_fixed = df.copy()\n",
    "        \n",
    "        # Define columns that should be numeric\n",
    "        numeric_columns_to_fix = ['humidity', 'wind_speed', 'pressure']\n",
    "        \n",
    "        print(f\"\\n=== FIXING DATA TYPES FOR {dataset_name} ===\")\n",
    "        \n",
    "        for col in numeric_columns_to_fix:\n",
    "            if col in df_fixed.columns:\n",
    "                print(f\"\\nProcessing {col}:\")\n",
    "                print(f\"Original dtype: {df_fixed[col].dtype}\")\n",
    "                \n",
    "                # Check for non-numeric values before conversion\n",
    "                if df_fixed[col].dtype == 'object':\n",
    "                    # Display unique non-numeric values\n",
    "                    try:\n",
    "                        # Try to convert to numeric and see what fails\n",
    "                        numeric_conversion = pd.to_numeric(df_fixed[col], errors='coerce')\n",
    "                        non_numeric_mask = pd.isna(numeric_conversion) & df_fixed[col].notna()\n",
    "                        \n",
    "                        if non_numeric_mask.any():\n",
    "                            print(f\"Non-numeric values found in {col}:\")\n",
    "                            non_numeric_values = df_fixed.loc[non_numeric_mask, col].value_counts()\n",
    "                            print(non_numeric_values.head(10))\n",
    "                            \n",
    "                            # Handle common non-numeric patterns\n",
    "                            df_fixed[col] = df_fixed[col].astype(str)\n",
    "                            \n",
    "                            # Remove common problematic characters\n",
    "                            df_fixed[col] = df_fixed[col].str.replace(r'[^\\d.-]', '', regex=True)\n",
    "                            df_fixed[col] = df_fixed[col].str.strip()\n",
    "                            \n",
    "                            # Handle empty strings\n",
    "                            df_fixed[col] = df_fixed[col].replace('', np.nan)\n",
    "                            df_fixed[col] = df_fixed[col].replace('nan', np.nan)\n",
    "                            \n",
    "                        # Convert to numeric\n",
    "                        df_fixed[col] = pd.to_numeric(df_fixed[col], errors='coerce')\n",
    "                        \n",
    "                        print(f\"Converted dtype: {df_fixed[col].dtype}\")\n",
    "                        print(f\"Missing values after conversion: {df_fixed[col].isnull().sum()}\")\n",
    "                        print(f\"Valid numeric values: {df_fixed[col].notna().sum()}\")\n",
    "                        \n",
    "                        # Basic statistics for converted column\n",
    "                        if df_fixed[col].notna().any():\n",
    "                            print(f\"Min: {df_fixed[col].min():.3f}\")\n",
    "                            print(f\"Max: {df_fixed[col].max():.3f}\")\n",
    "                            print(f\"Mean: {df_fixed[col].mean():.3f}\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error converting {col}: {str(e)}\")\n",
    "                else:\n",
    "                    print(f\"{col} is already numeric type: {df_fixed[col].dtype}\")\n",
    "        \n",
    "        return df_fixed\n",
    "        \n",
    "    def load_and_prepare_data(self):\n",
    "        \"\"\"\n",
    "        Load raw data, fix data types, and apply imputation pipeline\n",
    "        \"\"\"\n",
    "        print(\"Loading raw data...\")\n",
    "        self.df_raw = pd.read_csv(self.data_path)\n",
    "        print(f\"Raw dataset shape: {self.df_raw.shape}\")\n",
    "        print(f\"Missing values in raw data:\\n{self.df_raw.isnull().sum()[self.df_raw.isnull().sum() > 0]}\")\n",
    "        \n",
    "        # Step 1: Fix data types BEFORE imputation\n",
    "        print(\"\\nStep 1: Fixing data types...\")\n",
    "        self.df_fixed = self.fix_data_types(self.df_raw, \"TRAINING DATA\")\n",
    "        \n",
    "        # Verify the fixes\n",
    "        print(\"\\n=== DATA TYPE VERIFICATION ===\")\n",
    "        print(\"Data types after fixing:\")\n",
    "        for col in ['humidity', 'wind_speed', 'pressure']:\n",
    "            if col in self.df_fixed.columns:\n",
    "                print(f\"{col}: {self.df_fixed[col].dtype}\")\n",
    "        \n",
    "        # Step 2: Initialize and apply imputation pipeline (WITHOUT feature creation)\n",
    "        print(\"\\nStep 2: Applying imputation pipeline...\")\n",
    "        self.imputer = ImputationPipeline()\n",
    "        self.df_imputed = self.imputer.fit_transform(self.df_fixed)\n",
    "        \n",
    "        print(f\"Dataset shape after imputation: {self.df_imputed.shape}\")\n",
    "        remaining_missing = self.df_imputed.isnull().sum().sum()\n",
    "        print(f\"Remaining missing values after imputation: {remaining_missing}\")\n",
    "        \n",
    "        # Step 3: NOW create features AFTER imputation is complete\n",
    "        print(\"\\nStep 3: Creating engineered features...\")\n",
    "        from utils.feature_engineering import SolarFeatureEngineering\n",
    "        feature_engineer = SolarFeatureEngineering()\n",
    "        self.df = feature_engineer.create_solar_features(self.df_imputed)\n",
    "        print(f\"Dataset shape after feature engineering: {self.df.shape}\")\n",
    "        \n",
    "        # Verify no missing values in new features\n",
    "        new_missing = self.df.isnull().sum().sum()\n",
    "        if new_missing > 0:\n",
    "            print(f\"Warning: {new_missing} missing values found after feature engineering\")\n",
    "            print(\"Missing values by column:\")\n",
    "            print(self.df.isnull().sum()[self.df.isnull().sum() > 0])\n",
    "\n",
    "        # Step 4: Drop selected features if specified\n",
    "        if self.features_to_drop:\n",
    "            print(f\"\\nStep 4: Dropping features: {self.features_to_drop}\")\n",
    "            available_features = [col for col in self.features_to_drop if col in self.df.columns]\n",
    "            unavailable_features = [col for col in self.features_to_drop if col not in self.df.columns]\n",
    "            \n",
    "            if available_features:\n",
    "                self.df = self.df.drop(columns=available_features)\n",
    "                print(f\"Dropped features: {available_features}\")\n",
    "            \n",
    "            if unavailable_features:\n",
    "                print(f\"Warning: Features not found in dataset: {unavailable_features}\")\n",
    "            \n",
    "            print(f\"Dataset shape after dropping features: {self.df.shape}\")\n",
    "        \n",
    "        # Separate features and target\n",
    "        self.target_col = 'efficiency'\n",
    "        self.feature_cols = [col for col in self.df.columns if col != self.target_col]\n",
    "        \n",
    "        # Identify categorical and numerical columns\n",
    "        self.categorical_cols = self.df[self.feature_cols].select_dtypes(include=['object']).columns.tolist()\n",
    "        self.numerical_cols = self.df[self.feature_cols].select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "        \n",
    "        print(f\"Categorical columns: {self.categorical_cols}\")\n",
    "        print(f\"Numerical columns: {self.numerical_cols}\")\n",
    "        print(f\"Total features: {len(self.feature_cols)}\")\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def create_preprocessing_pipeline(self):\n",
    "        \"\"\"\n",
    "        Create preprocessing pipeline for numerical and categorical features\n",
    "        \"\"\"\n",
    "        print(\"Creating preprocessing pipeline...\")\n",
    "        \n",
    "        # For neural networks, we need StandardScaler instead of RobustScaler\n",
    "        # as neural networks work better with standardized inputs\n",
    "        numerical_pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler())  # Neural networks prefer StandardScaler\n",
    "        ])\n",
    "        \n",
    "        # Categorical preprocessing pipeline\n",
    "        categorical_pipeline = Pipeline([\n",
    "            ('encoder', 'passthrough')  # Will be handled separately\n",
    "        ])\n",
    "        \n",
    "        # Create preprocessor\n",
    "        self.preprocessor = ColumnTransformer([\n",
    "            ('num', numerical_pipeline, self.numerical_cols),\n",
    "            ('cat', categorical_pipeline, self.categorical_cols)\n",
    "        ])\n",
    "        \n",
    "        return self.preprocessor\n",
    "    \n",
    "    def prepare_train_test_split(self):\n",
    "        \"\"\"\n",
    "        Prepare train-test split with proper preprocessing\n",
    "        \"\"\"\n",
    "        print(\"Preparing train-test split...\")\n",
    "        \n",
    "        X = self.df[self.feature_cols].copy()\n",
    "        y = self.df[self.target_col].copy()\n",
    "        \n",
    "        # Store original target values for later use\n",
    "        self.y_original = y.copy()\n",
    "        \n",
    "        # Apply power transformation to target if it's skewed\n",
    "        self.target_transformer = PowerTransformer(method='yeo-johnson')\n",
    "        y_transformed = self.target_transformer.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # Train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y_transformed, test_size=self.test_size, random_state=self.random_state, stratify=None\n",
    "        )\n",
    "        \n",
    "        # Also split original target for evaluation\n",
    "        _, _, self.y_train_original, self.y_test_original = train_test_split(\n",
    "            X, y, test_size=self.test_size, random_state=self.random_state, stratify=None\n",
    "        )\n",
    "        \n",
    "        # Handle categorical encoding\n",
    "        self.label_encoders = {}\n",
    "        for col in self.categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
    "            X_test[col] = le.transform(X_test[col].astype(str))\n",
    "            self.label_encoders[col] = le\n",
    "        \n",
    "        # Apply numerical preprocessing\n",
    "        X_train_scaled = self.preprocessor.fit_transform(X_train)\n",
    "        X_test_scaled = self.preprocessor.transform(X_test)\n",
    "        \n",
    "        # Convert back to DataFrame for easier handling\n",
    "        feature_names = self.numerical_cols + self.categorical_cols\n",
    "        X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_names)\n",
    "        X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_names)\n",
    "        \n",
    "        self.X_train, self.X_test = X_train_scaled, X_test_scaled\n",
    "        self.y_train, self.y_test = y_train, y_test\n",
    "        \n",
    "        print(f\"Training set shape: {self.X_train.shape}\")\n",
    "        print(f\"Test set shape: {self.X_test.shape}\")\n",
    "        \n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "    \n",
    "    def define_models(self):\n",
    "        \"\"\"\n",
    "        Define all models to be tested including ANN\n",
    "        \"\"\"\n",
    "        print(\"Defining models...\")\n",
    "        \n",
    "        self.models = {\n",
    "            'Linear Regression': LinearRegression(),\n",
    "            'Ridge': Ridge(random_state=self.random_state),\n",
    "            'Lasso': Lasso(random_state=self.random_state),\n",
    "            'ElasticNet': ElasticNet(random_state=self.random_state),\n",
    "            'Decision Tree': DecisionTreeRegressor(random_state=self.random_state),\n",
    "            'Random Forest': RandomForestRegressor(random_state=self.random_state, n_jobs=-1),\n",
    "            'Extra Trees': ExtraTreesRegressor(random_state=self.random_state, n_jobs=-1),\n",
    "            'Gradient Boosting': GradientBoostingRegressor(random_state=self.random_state),\n",
    "            'XGBoost': XGBRegressor(random_state=self.random_state, eval_metric='rmse'),\n",
    "            'LightGBM': LGBMRegressor(random_state=self.random_state, verbose=-1),\n",
    "            'CatBoost': CatBoostRegressor(random_state=self.random_state, verbose=False),\n",
    "            'KNN': KNeighborsRegressor(),\n",
    "            'SVR': SVR(),\n",
    "            # 'ANN': ANNRegressor(verbose=0)  # Use custom ANN wrapper\n",
    "        }\n",
    "        \n",
    "        return self.models\n",
    "    \n",
    "    def inverse_transform_predictions(self, y_pred):\n",
    "        \"\"\"\n",
    "        Apply inverse transformation to predictions to get them back to original scale\n",
    "        \"\"\"\n",
    "        y_pred_reshaped = y_pred.reshape(-1, 1)\n",
    "        y_pred_original = self.target_transformer.inverse_transform(y_pred_reshaped).flatten()\n",
    "        return y_pred_original\n",
    "    \n",
    "    def custom_score_function(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Custom scoring function as per problem statement\n",
    "        Score = 100*(1-sqrt(MSE))\n",
    "        Note: This should be calculated on original scale, not transformed scale\n",
    "        \"\"\"\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        score = 100 * (1 - np.sqrt(mse))\n",
    "        return score\n",
    "    \n",
    "    def evaluate_base_models(self):\n",
    "        \"\"\"\n",
    "        Evaluate all base models using cross-validation\n",
    "        \"\"\"\n",
    "        print(\"Evaluating base models...\")\n",
    "        \n",
    "        self.results = {}\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            print(f\"Training {name}...\")\n",
    "            \n",
    "            try:\n",
    "                # Cross-validation scores (on transformed target)\n",
    "                if name == 'ANN':\n",
    "                    # For ANN, use fewer CV folds due to computational cost\n",
    "                    cv_scores = cross_val_score(model, self.X_train, self.y_train, cv=3, \n",
    "                                              scoring='neg_mean_squared_error', n_jobs=1)\n",
    "                else:\n",
    "                    cv_scores = cross_val_score(model, self.X_train, self.y_train, cv=5, \n",
    "                                              scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "                \n",
    "                # Fit model for additional metrics\n",
    "                model.fit(self.X_train, self.y_train)\n",
    "                \n",
    "                # Get predictions on transformed scale\n",
    "                y_pred_train_transformed = model.predict(self.X_train)\n",
    "                y_pred_test_transformed = model.predict(self.X_test)\n",
    "                \n",
    "                # Transform predictions back to original scale\n",
    "                y_pred_train_original = self.inverse_transform_predictions(y_pred_train_transformed)\n",
    "                y_pred_test_original = self.inverse_transform_predictions(y_pred_test_transformed)\n",
    "                \n",
    "                # Calculate metrics on ORIGINAL scale\n",
    "                train_rmse = np.sqrt(mean_squared_error(self.y_train_original, y_pred_train_original))\n",
    "                test_rmse = np.sqrt(mean_squared_error(self.y_test_original, y_pred_test_original))\n",
    "                train_r2 = r2_score(self.y_train_original, y_pred_train_original)\n",
    "                test_r2 = r2_score(self.y_test_original, y_pred_test_original)\n",
    "                \n",
    "                # Custom score on original scale\n",
    "                train_custom_score = self.custom_score_function(self.y_train_original, y_pred_train_original)\n",
    "                test_custom_score = self.custom_score_function(self.y_test_original, y_pred_test_original)\n",
    "                \n",
    "                # CV RMSE on transformed scale (for comparison)\n",
    "                cv_rmse_transformed = np.sqrt(-cv_scores.mean())\n",
    "                \n",
    "                self.results[name] = {\n",
    "                    'CV_RMSE_transformed': cv_rmse_transformed,\n",
    "                    'CV_RMSE_std': np.sqrt(cv_scores.std()),\n",
    "                    'Train_RMSE': train_rmse,\n",
    "                    'Test_RMSE': test_rmse,\n",
    "                    'Train_R2': train_r2,\n",
    "                    'Test_R2': test_r2,\n",
    "                    'Train_Custom_Score': train_custom_score,\n",
    "                    'Test_Custom_Score': test_custom_score,\n",
    "                    'Model': model\n",
    "                }\n",
    "                \n",
    "                print(f\"  âœ“ {name} completed - Test Custom Score: {test_custom_score:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  âœ— Error training {name}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def get_hyperparameter_grids(self):\n",
    "        \"\"\"\n",
    "        Define hyperparameter grids for top performing models including ANN\n",
    "        \"\"\"\n",
    "        param_grids = {\n",
    "            'Random Forest': {\n",
    "                'n_estimators': [100, 200, 300],\n",
    "                'max_depth': [10, 20, None],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4],\n",
    "                'max_features': ['sqrt', 'log2']\n",
    "            },\n",
    "            'XGBoost': {\n",
    "                'n_estimators': [100, 200, 300],\n",
    "                'max_depth': [3, 6, 9],\n",
    "                'learning_rate': [0.01, 0.1, 0.2],\n",
    "                'subsample': [0.8, 0.9, 1.0],\n",
    "                'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "            },\n",
    "            'LightGBM': {\n",
    "                'n_estimators': [100, 200, 300],\n",
    "                'max_depth': [3, 6, 9],\n",
    "                'learning_rate': [0.01, 0.1, 0.2],\n",
    "                'num_leaves': [31, 50, 100],\n",
    "                'subsample': [0.8, 0.9, 1.0]\n",
    "            },\n",
    "            'Gradient Boosting': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [3, 5, 7],\n",
    "                'learning_rate': [0.01, 0.1, 0.2],\n",
    "                'subsample': [0.8, 0.9, 1.0]\n",
    "            },\n",
    "            'Ridge': {\n",
    "                'alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "            },\n",
    "            'Lasso': {\n",
    "                'alpha': [0.001, 0.01, 0.1, 1.0]\n",
    "            },\n",
    "            'ANN': {\n",
    "                'neurons': [64, 128, 256],\n",
    "                'layers': [2, 3, 4],\n",
    "                'dropout_rate': [0.2, 0.3, 0.4],\n",
    "                'learning_rate': [0.001, 0.01],\n",
    "                'l2_reg': [0.001, 0.01, 0.1],\n",
    "                'epochs': [150, 250],\n",
    "                'batch_size': [16, 32, 64]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return param_grids\n",
    "    \n",
    "    def hyperparameter_tuning(self, top_n=5):\n",
    "        \"\"\"\n",
    "        Perform hyperparameter tuning for top N models including ANN\n",
    "        \"\"\"\n",
    "        print(f\"Performing hyperparameter tuning for top {top_n} models...\")\n",
    "        \n",
    "        # Sort models by test RMSE\n",
    "        sorted_models = sorted(self.results.items(), key=lambda x: x[1]['Test_RMSE'])\n",
    "        top_models = [name for name, _ in sorted_models[:top_n]]\n",
    "        \n",
    "        param_grids = self.get_hyperparameter_grids()\n",
    "        tuned_results = {}\n",
    "        \n",
    "        for model_name in top_models:\n",
    "            if model_name in param_grids:\n",
    "                print(f\"Tuning {model_name}...\")\n",
    "                \n",
    "                try:\n",
    "                    base_model = self.models[model_name]\n",
    "                    param_grid = param_grids[model_name]\n",
    "                    \n",
    "                    # Use different search strategies for different models\n",
    "                    if model_name == 'ANN':\n",
    "                        # Use fewer iterations for ANN due to computational cost\n",
    "                        grid_search = RandomizedSearchCV(\n",
    "                            base_model, param_grid, n_iter=10, cv=3,\n",
    "                            scoring='neg_mean_squared_error', n_jobs=1,\n",
    "                            random_state=self.random_state\n",
    "                        )\n",
    "                    else:\n",
    "                        # Use RandomizedSearchCV for faster tuning\n",
    "                        grid_search = RandomizedSearchCV(\n",
    "                            base_model, param_grid, n_iter=20, cv=5,\n",
    "                            scoring='neg_mean_squared_error', n_jobs=-1,\n",
    "                            random_state=self.random_state\n",
    "                        )\n",
    "                    \n",
    "                    grid_search.fit(self.X_train, self.y_train)\n",
    "                    \n",
    "                    # Evaluate best model\n",
    "                    best_model = grid_search.best_estimator_\n",
    "                    \n",
    "                    # Get predictions on transformed scale\n",
    "                    y_pred_train_transformed = best_model.predict(self.X_train)\n",
    "                    y_pred_test_transformed = best_model.predict(self.X_test)\n",
    "                    \n",
    "                    # Transform predictions back to original scale\n",
    "                    y_pred_train_original = self.inverse_transform_predictions(y_pred_train_transformed)\n",
    "                    y_pred_test_original = self.inverse_transform_predictions(y_pred_test_transformed)\n",
    "                    \n",
    "                    tuned_results[f'{model_name}_Tuned'] = {\n",
    "                        'Best_Params': grid_search.best_params_,\n",
    "                        'CV_RMSE_transformed': np.sqrt(-grid_search.best_score_),\n",
    "                        'Train_RMSE': np.sqrt(mean_squared_error(self.y_train_original, y_pred_train_original)),\n",
    "                        'Test_RMSE': np.sqrt(mean_squared_error(self.y_test_original, y_pred_test_original)),\n",
    "                        'Train_R2': r2_score(self.y_train_original, y_pred_train_original),\n",
    "                        'Test_R2': r2_score(self.y_test_original, y_pred_test_original),\n",
    "                        'Train_Custom_Score': self.custom_score_function(self.y_train_original, y_pred_train_original),\n",
    "                        'Test_Custom_Score': self.custom_score_function(self.y_test_original, y_pred_test_original),\n",
    "                        'Model': best_model\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"  âœ“ {model_name} tuning completed\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  âœ— Error tuning {model_name}: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        self.tuned_results = tuned_results\n",
    "        return tuned_results\n",
    "    \n",
    "    def create_stacking_models(self, n_best=2):\n",
    "        \"\"\"\n",
    "        Create stacking regressor using the top N performing tuned models as base estimators.\n",
    "        \n",
    "        Parameters:\n",
    "        n_best: Number of best models to use as base estimators (default: 2)\n",
    "        \"\"\"\n",
    "        print(f\"\\nCreating stacking regressor with top {n_best} tuned models...\")\n",
    "\n",
    "        if not hasattr(self, 'tuned_results') or not self.tuned_results:\n",
    "            raise ValueError(\"No tuned models found. Please tune models before creating stacking models.\")\n",
    "\n",
    "        # Step 1: Create a dictionary of tuned models only\n",
    "        best_models_by_type = {}\n",
    "\n",
    "        for name, results in self.tuned_results.items():\n",
    "            # Extract the base model type from tuned name (e.g., \"ANN_Tuned\" -> \"ann\")\n",
    "            if name.endswith('_Tuned'):\n",
    "                base_name = name[:-6]  # Remove \"_Tuned\"\n",
    "            else:\n",
    "                base_name = name\n",
    "            \n",
    "            model_type = base_name.lower().replace(' ', '_')\n",
    "            best_models_by_type[model_type] = {\n",
    "                'name': name,\n",
    "                'results': results,\n",
    "                'is_tuned': True\n",
    "            }\n",
    "\n",
    "        # Step 2: Sort tuned models by performance\n",
    "        sorted_models = sorted(\n",
    "            best_models_by_type.items(),\n",
    "            key=lambda x: x[1]['results']['Test_Custom_Score'],\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "        top_models = sorted_models[:n_best]\n",
    "\n",
    "        print(f\"Selected base estimators for stacking (tuned only):\")\n",
    "        for i, (model_type, model_info) in enumerate(top_models, 1):\n",
    "            print(f\"  {i}. {model_info['name']} - Test Custom Score: {model_info['results']['Test_Custom_Score']:.4f}\")\n",
    "\n",
    "        # Step 3: Prepare base estimators\n",
    "        base_estimators = []\n",
    "        for model_type, model_info in top_models:\n",
    "            estimator = model_info['results']['Model']\n",
    "            base_estimators.append((model_type, estimator))\n",
    "\n",
    "        estimator_names = [name for name, _ in base_estimators]\n",
    "        if len(estimator_names) != len(set(estimator_names)):\n",
    "            raise ValueError(f\"Duplicate estimator names found: {estimator_names}\")\n",
    "\n",
    "        print(f\"Base estimator names: {estimator_names}\")\n",
    "\n",
    "        # Step 4: Define meta-regressors\n",
    "        meta_regressors = {\n",
    "            'Linear': LinearRegression(),\n",
    "            'Ridge': Ridge(alpha=1.0, random_state=self.random_state),\n",
    "            'Lasso': Lasso(alpha=0.1, random_state=self.random_state),\n",
    "            'ElasticNet': ElasticNet(alpha=0.1, random_state=self.random_state),\n",
    "            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=self.random_state, n_jobs=-1)\n",
    "        }\n",
    "\n",
    "        stacking_models = {}\n",
    "\n",
    "        for meta_name, meta_regressor in meta_regressors.items():\n",
    "            stacking_name = f\"Stacking_{meta_name}\"\n",
    "\n",
    "            stacking_model = StackingRegressor(\n",
    "                estimators=base_estimators,\n",
    "                final_estimator=meta_regressor,\n",
    "                cv=3,\n",
    "                n_jobs=-1,\n",
    "                passthrough=False\n",
    "            )\n",
    "\n",
    "            stacking_models[stacking_name] = stacking_model\n",
    "\n",
    "        # Step 5: Train and evaluate stacking models\n",
    "        self.stacking_results = {}\n",
    "\n",
    "        for stacking_name, stacking_model in stacking_models.items():\n",
    "            print(f\"\\nTraining {stacking_name}...\")\n",
    "\n",
    "            try:\n",
    "                stacking_model.fit(self.X_train, self.y_train)\n",
    "\n",
    "                y_pred_train_transformed = stacking_model.predict(self.X_train)\n",
    "                y_pred_test_transformed = stacking_model.predict(self.X_test)\n",
    "\n",
    "                y_pred_train_original = self.inverse_transform_predictions(y_pred_train_transformed)\n",
    "                y_pred_test_original = self.inverse_transform_predictions(y_pred_test_transformed)\n",
    "\n",
    "                train_rmse = np.sqrt(mean_squared_error(self.y_train_original, y_pred_train_original))\n",
    "                test_rmse = np.sqrt(mean_squared_error(self.y_test_original, y_pred_test_original))\n",
    "                train_r2 = r2_score(self.y_train_original, y_pred_train_original)\n",
    "                test_r2 = r2_score(self.y_test_original, y_pred_test_original)\n",
    "\n",
    "                train_custom_score = self.custom_score_function(self.y_train_original, y_pred_train_original)\n",
    "                test_custom_score = self.custom_score_function(self.y_test_original, y_pred_test_original)\n",
    "\n",
    "                cv_scores = cross_val_score(stacking_model, self.X_train, self.y_train,\n",
    "                                            cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "                cv_rmse_transformed = np.sqrt(-cv_scores.mean())\n",
    "\n",
    "                base_estimator_info = []\n",
    "                for model_type, model_info in top_models:\n",
    "                    base_estimator_info.append({\n",
    "                        'name': model_info['name'],\n",
    "                        'type': model_type,\n",
    "                        'is_tuned': True,\n",
    "                        'score': model_info['results']['Test_Custom_Score']\n",
    "                    })\n",
    "\n",
    "                self.stacking_results[stacking_name] = {\n",
    "                    'Base_Estimators': base_estimator_info,\n",
    "                    'Meta_Regressor': meta_name,\n",
    "                    'CV_RMSE_transformed': cv_rmse_transformed,\n",
    "                    'CV_RMSE_std': np.sqrt(cv_scores.std()),\n",
    "                    'Train_RMSE': train_rmse,\n",
    "                    'Test_RMSE': test_rmse,\n",
    "                    'Train_R2': train_r2,\n",
    "                    'Test_R2': test_r2,\n",
    "                    'Train_Custom_Score': train_custom_score,\n",
    "                    'Test_Custom_Score': test_custom_score,\n",
    "                    'Model': stacking_model\n",
    "                }\n",
    "\n",
    "                print(f\"  âœ“ {stacking_name} completed - Test Custom Score: {test_custom_score:.4f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  âœ— Error training {stacking_name}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        # Step 6: Select best stacking model\n",
    "        if self.stacking_results:\n",
    "            best_stacking_name = max(self.stacking_results.keys(),\n",
    "                                    key=lambda x: self.stacking_results[x]['Test_Custom_Score'])\n",
    "            self.best_stacking_model = self.stacking_results[best_stacking_name]['Model']\n",
    "\n",
    "            print(f\"\\nBest stacking model: {best_stacking_name}\")\n",
    "            print(f\"Test Custom Score: {self.stacking_results[best_stacking_name]['Test_Custom_Score']:.4f}\")\n",
    "            print(f\"Test RMSE: {self.stacking_results[best_stacking_name]['Test_RMSE']:.4f}\")\n",
    "            print(f\"Test RÂ²: {self.stacking_results[best_stacking_name]['Test_R2']:.4f}\")\n",
    "\n",
    "            print(\"Base estimators used:\")\n",
    "            for estimator_info in self.stacking_results[best_stacking_name]['Base_Estimators']:\n",
    "                print(f\"  - {estimator_info['name']} (Tuned): {estimator_info['score']:.4f}\")\n",
    "\n",
    "        return self.stacking_results\n",
    "\n",
    "\n",
    "    def compare_all_models(self):\n",
    "        \"\"\"\n",
    "        Compare all models including base, tuned, and stacking models\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"COMPREHENSIVE MODEL COMPARISON\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Combine all results\n",
    "        all_model_results = {}\n",
    "        \n",
    "        # Add base model results with \"Base_\" prefix for clarity\n",
    "        for name, results in self.results.items():\n",
    "            all_model_results[f\"Base_{name}\"] = results\n",
    "        \n",
    "        # Add tuned model results (these already have clear names)\n",
    "        if hasattr(self, 'tuned_results'):\n",
    "            for name, results in self.tuned_results.items():\n",
    "                all_model_results[name] = results\n",
    "        \n",
    "        # Add stacking model results\n",
    "        if hasattr(self, 'stacking_results'):\n",
    "            for name, results in self.stacking_results.items():\n",
    "                all_model_results[name] = results\n",
    "        \n",
    "        # Create comparison DataFrame\n",
    "        comparison_data = []\n",
    "        for name, results in all_model_results.items():\n",
    "            comparison_data.append({\n",
    "                'Model': name,\n",
    "                'Test_RMSE': results['Test_RMSE'],\n",
    "                'Test_R2': results['Test_R2'],\n",
    "                'Test_Custom_Score': results['Test_Custom_Score'],\n",
    "                'Train_Custom_Score': results['Train_Custom_Score'],\n",
    "                'Overfitting': results['Train_Custom_Score'] - results['Test_Custom_Score']\n",
    "            })\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        comparison_df = comparison_df.sort_values('Test_Custom_Score', ascending=False)\n",
    "        \n",
    "        print(\"\\nTop 10 Models by Test Custom Score:\")\n",
    "        print(\"-\" * 95)\n",
    "        print(f\"{'Model':<30} {'Test_RMSE':<12} {'Test_RÂ²':<10} {'Test_Score':<12} {'Overfitting':<12} {'Type':<15}\")\n",
    "        print(\"-\" * 95)\n",
    "        \n",
    "        for _, row in comparison_df.head(10).iterrows():\n",
    "            # Determine model type\n",
    "            model_name = row['Model']\n",
    "            if model_name.startswith('Base_'):\n",
    "                model_type = 'Base'\n",
    "            elif model_name.endswith('_Tuned'):\n",
    "                model_type = 'Tuned'\n",
    "            elif model_name.startswith('Stacking_'):\n",
    "                model_type = 'Stacking'\n",
    "            else:\n",
    "                model_type = 'Other'\n",
    "            \n",
    "            print(f\"{model_name:<30} {row['Test_RMSE']:<12.4f} {row['Test_R2']:<10.4f} \"\n",
    "                f\"{row['Test_Custom_Score']:<12.4f} {row['Overfitting']:<12.4f} {model_type:<15}\")\n",
    "        \n",
    "        # Identify the overall best model\n",
    "        best_model_name = comparison_df.iloc[0]['Model']\n",
    "        best_model_results = all_model_results[best_model_name]\n",
    "        \n",
    "        print(f\"\\nðŸ† BEST OVERALL MODEL: {best_model_name}\")\n",
    "        print(f\"   Test Custom Score: {best_model_results['Test_Custom_Score']:.4f}\")\n",
    "        print(f\"   Test RMSE: {best_model_results['Test_RMSE']:.4f}\")\n",
    "        print(f\"   Test RÂ²: {best_model_results['Test_R2']:.4f}\")\n",
    "        \n",
    "        # Show additional information for stacking models\n",
    "        if best_model_name.startswith('Stacking_') and hasattr(self, 'stacking_results'):\n",
    "            stacking_info = self.stacking_results[best_model_name]\n",
    "            print(f\"   Meta Regressor: {stacking_info['Meta_Regressor']}\")\n",
    "            print(f\"   Base Estimators:\")\n",
    "            for estimator_info in stacking_info['Base_Estimators']:\n",
    "                status = \"Tuned\" if estimator_info['is_tuned'] else \"Base\"\n",
    "                print(f\"     - {estimator_info['name']} ({status}): {estimator_info['score']:.4f}\")\n",
    "        \n",
    "        # Store the best model\n",
    "        self.best_model = best_model_results['Model']\n",
    "        self.best_model_name = best_model_name\n",
    "        \n",
    "        return comparison_df\n",
    "\n",
    "    def get_model_summary(self):\n",
    "        \"\"\"\n",
    "        Get a comprehensive summary of the model selection process\n",
    "        \"\"\"\n",
    "        summary = {\n",
    "            'dataset_info': {\n",
    "                'original_shape': self.df_raw.shape if hasattr(self, 'df_raw') else None,\n",
    "                'final_shape': self.df.shape if hasattr(self, 'df') else None,\n",
    "                'features_dropped': self.features_to_drop,\n",
    "                'categorical_features': len(self.categorical_cols) if hasattr(self, 'categorical_cols') else 0,\n",
    "                'numerical_features': len(self.numerical_cols) if hasattr(self, 'numerical_cols') else 0\n",
    "            },\n",
    "            'model_counts': {\n",
    "                'base_models': len(self.results) if hasattr(self, 'results') else 0,\n",
    "                'tuned_models': len(self.tuned_results) if hasattr(self, 'tuned_results') else 0,\n",
    "                'stacking_models': len(self.stacking_results) if hasattr(self, 'stacking_results') else 0\n",
    "            },\n",
    "            'best_model': {\n",
    "                'name': self.best_model_name if hasattr(self, 'best_model_name') else None,\n",
    "                'test_custom_score': None,\n",
    "                'test_rmse': None,\n",
    "                'test_r2': None\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Add best model metrics if available\n",
    "        if hasattr(self, 'best_model_name'):\n",
    "            # Find the best model results\n",
    "            all_results = {**self.results}\n",
    "            if hasattr(self, 'tuned_results'):\n",
    "                all_results.update(self.tuned_results)\n",
    "            if hasattr(self, 'stacking_results'):\n",
    "                all_results.update(self.stacking_results)\n",
    "            \n",
    "            if self.best_model_name in all_results:\n",
    "                best_results = all_results[self.best_model_name]\n",
    "                summary['best_model'].update({\n",
    "                    'test_custom_score': best_results['Test_Custom_Score'],\n",
    "                    'test_rmse': best_results['Test_RMSE'],\n",
    "                    'test_r2': best_results['Test_R2']\n",
    "                })\n",
    "        \n",
    "        return summary\n",
    "\n",
    "    def run_complete_pipeline(self):\n",
    "        \"\"\"\n",
    "        Run the complete model selection pipeline including stacking\n",
    "        \"\"\"\n",
    "        print(\"ðŸš€ STARTING COMPLETE MODEL SELECTION PIPELINE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Step 1: Load and prepare data\n",
    "        print(\"\\nðŸ“Š STEP 1: Data Loading and Preparation\")\n",
    "        self.load_and_prepare_data()\n",
    "        \n",
    "        # Step 2: Create preprocessing pipeline\n",
    "        print(\"\\nðŸ”§ STEP 2: Creating Preprocessing Pipeline\")\n",
    "        self.create_preprocessing_pipeline()\n",
    "        \n",
    "        # Step 3: Prepare train-test split\n",
    "        print(\"\\nâœ‚ï¸ STEP 3: Train-Test Split\")\n",
    "        self.prepare_train_test_split()\n",
    "        \n",
    "        # Step 4: Define and evaluate base models\n",
    "        print(\"\\nðŸ¤– STEP 4: Base Model Evaluation\")\n",
    "        self.define_models()\n",
    "        self.evaluate_base_models()\n",
    "        \n",
    "        # Step 5: Hyperparameter tuning\n",
    "        print(\"\\nâš™ï¸ STEP 5: Hyperparameter Tuning\")\n",
    "        self.hyperparameter_tuning(top_n=5)\n",
    "        \n",
    "        # Step 6: Create stacking models\n",
    "        print(\"\\nðŸ—ï¸ STEP 6: Stacking Model Creation\")\n",
    "        self.create_stacking_models(n_best=2)\n",
    "        \n",
    "        # Step 7: Compare all models\n",
    "        print(\"\\nðŸ“ˆ STEP 7: Final Model Comparison\")\n",
    "        comparison_df = self.compare_all_models()\n",
    "        \n",
    "        # Step 8: Generate summary\n",
    "        print(\"\\nðŸ“‹ STEP 8: Pipeline Summary\")\n",
    "        summary = self.get_model_summary()\n",
    "        \n",
    "        print(\"\\nâœ… PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "        print(f\"Best Model: {summary['best_model']['name']}\")\n",
    "        print(f\"Final Test Score: {summary['best_model']['test_custom_score']:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'comparison_df': comparison_df,\n",
    "            'summary': summary,\n",
    "            'best_model': self.best_model,\n",
    "            'best_model_name': self.best_model_name\n",
    "        }\n",
    "    \n",
    "    def select_best_model(self):\n",
    "        \"\"\"\n",
    "        Select the best model from all evaluated models (base, tuned, and stacking)\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SELECTING BEST MODEL\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Combine all results\n",
    "        all_results = {}\n",
    "        \n",
    "        # Add base model results\n",
    "        if hasattr(self, 'results'):\n",
    "            for name, results in self.results.items():\n",
    "                all_results[f\"Base_{name}\"] = results\n",
    "        \n",
    "        # Add tuned model results\n",
    "        if hasattr(self, 'tuned_results'):\n",
    "            for name, results in self.tuned_results.items():\n",
    "                all_results[name] = results\n",
    "        \n",
    "        # Add stacking model results\n",
    "        if hasattr(self, 'stacking_results'):\n",
    "            for name, results in self.stacking_results.items():\n",
    "                all_results[name] = results\n",
    "        \n",
    "        if not all_results:\n",
    "            raise ValueError(\"No models have been evaluated yet!\")\n",
    "        \n",
    "        # Find best model based on Test Custom Score\n",
    "        best_model_name = max(all_results.keys(), \n",
    "                            key=lambda x: all_results[x]['Test_Custom_Score'])\n",
    "        \n",
    "        best_results = all_results[best_model_name]\n",
    "        \n",
    "        # Store best model information\n",
    "        self.best_model = best_results['Model']\n",
    "        self.best_model_name = best_model_name\n",
    "        self.best_score = best_results['Test_Custom_Score']\n",
    "        self.best_results = best_results\n",
    "        \n",
    "        print(f\"ðŸ† BEST MODEL SELECTED: {best_model_name}\")\n",
    "        print(f\"   Test Custom Score: {self.best_score:.4f}\")\n",
    "        print(f\"   Test RMSE: {best_results['Test_RMSE']:.4f}\")\n",
    "        print(f\"   Test RÂ²: {best_results['Test_R2']:.4f}\")\n",
    "        \n",
    "        # Display model-specific information\n",
    "        if 'Best_Params' in best_results:\n",
    "            print(f\"   Best Parameters: {best_results['Best_Params']}\")\n",
    "        elif 'Base_Estimators' in best_results:\n",
    "            print(f\"   Base Estimators: {best_results['Base_Estimators']}\")\n",
    "            print(f\"   Meta Regressor: {best_results['Meta_Regressor']}\")\n",
    "        \n",
    "        return self.best_model, self.best_model_name, self.best_score\n",
    "\n",
    "    def print_results_summary(self):\n",
    "        \"\"\"\n",
    "        Print a comprehensive summary of all results\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"COMPREHENSIVE RESULTS SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Dataset Information\n",
    "        print(f\"\\nðŸ“Š DATASET INFORMATION:\")\n",
    "        print(f\"   Original Shape: {self.df_raw.shape}\")\n",
    "        print(f\"   Final Shape: {self.df.shape}\")\n",
    "        print(f\"   Features Dropped: {len(self.features_to_drop)}\")\n",
    "        print(f\"   Categorical Features: {len(self.categorical_cols)}\")\n",
    "        print(f\"   Numerical Features: {len(self.numerical_cols)}\")\n",
    "        \n",
    "        # Model Performance Summary\n",
    "        print(f\"\\nðŸ¤– MODEL PERFORMANCE SUMMARY:\")\n",
    "        \n",
    "        # Base Models\n",
    "        if hasattr(self, 'results') and self.results:\n",
    "            print(f\"\\n   Base Models ({len(self.results)} models):\")\n",
    "            base_sorted = sorted(self.results.items(), \n",
    "                               key=lambda x: x[1]['Test_Custom_Score'], \n",
    "                               reverse=True)\n",
    "            for i, (name, results) in enumerate(base_sorted[:3], 1):\n",
    "                print(f\"      {i}. {name}: {results['Test_Custom_Score']:.4f}\")\n",
    "        \n",
    "        # Tuned Models\n",
    "        if hasattr(self, 'tuned_results') and self.tuned_results:\n",
    "            print(f\"\\n   Tuned Models ({len(self.tuned_results)} models):\")\n",
    "            tuned_sorted = sorted(self.tuned_results.items(), \n",
    "                                key=lambda x: x[1]['Test_Custom_Score'], \n",
    "                                reverse=True)\n",
    "            for i, (name, results) in enumerate(tuned_sorted, 1):\n",
    "                print(f\"      {i}. {name}: {results['Test_Custom_Score']:.4f}\")\n",
    "        \n",
    "        # Stacking Models\n",
    "        if hasattr(self, 'stacking_results') and self.stacking_results:\n",
    "            print(f\"\\n   Stacking Models ({len(self.stacking_results)} models):\")\n",
    "            stacking_sorted = sorted(self.stacking_results.items(), \n",
    "                                   key=lambda x: x[1]['Test_Custom_Score'], \n",
    "                                   reverse=True)\n",
    "            for i, (name, results) in enumerate(stacking_sorted, 1):\n",
    "                print(f\"      {i}. {name}: {results['Test_Custom_Score']:.4f}\")\n",
    "        \n",
    "        # Best Model Information\n",
    "        if hasattr(self, 'best_model_name'):\n",
    "            print(f\"\\nðŸ† BEST OVERALL MODEL:\")\n",
    "            print(f\"   Model: {self.best_model_name}\")\n",
    "            print(f\"   Test Custom Score: {self.best_score:.4f}\")\n",
    "            print(f\"   Test RMSE: {self.best_results['Test_RMSE']:.4f}\")\n",
    "            print(f\"   Test RÂ²: {self.best_results['Test_R2']:.4f}\")\n",
    "            print(f\"   Train Custom Score: {self.best_results['Train_Custom_Score']:.4f}\")\n",
    "            overfitting = self.best_results['Train_Custom_Score'] - self.best_results['Test_Custom_Score']\n",
    "            print(f\"   Overfitting Gap: {overfitting:.4f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "    def predict(self, X_new):\n",
    "        \"\"\"\n",
    "        Make predictions on new data using the complete pipeline\n",
    "        \"\"\"\n",
    "        if self.best_model is None:\n",
    "            raise ValueError(\"No model has been trained yet. Run the pipeline first.\")\n",
    "        \n",
    "        print(\"Making predictions on new data...\")\n",
    "        \n",
    "        # Step 1: Fix data types (same as training)\n",
    "        X_processed = self.fix_data_types(X_new.copy(), \"NEW DATA\")\n",
    "        \n",
    "        # Step 2: Apply imputation pipeline\n",
    "        X_processed = self.imputer.transform(X_processed)\n",
    "        \n",
    "        # Step 3: Apply feature engineering\n",
    "        from utils.feature_engineering import SolarFeatureEngineering\n",
    "        feature_engineer = SolarFeatureEngineering()\n",
    "        X_processed = feature_engineer.create_solar_features(X_processed)\n",
    "        \n",
    "        # Step 4: Drop features that were dropped during training\n",
    "        if self.features_to_drop:\n",
    "            available_features = [col for col in self.features_to_drop if col in X_processed.columns]\n",
    "            if available_features:\n",
    "                X_processed = X_processed.drop(columns=available_features)\n",
    "        \n",
    "        # Step 5: Select only the features used in training\n",
    "        X_processed = X_processed[self.feature_cols]\n",
    "        \n",
    "        # Step 6: Apply categorical encoding\n",
    "        for col in self.categorical_cols:\n",
    "            if col in X_processed.columns:\n",
    "                # Handle unseen categories by using the most frequent category\n",
    "                try:\n",
    "                    X_processed[col] = self.label_encoders[col].transform(X_processed[col].astype(str))\n",
    "                except ValueError:\n",
    "                    # If unseen categories, replace with most frequent\n",
    "                    most_frequent_encoded = 0  # Assuming first category is most frequent\n",
    "                    X_processed[col] = X_processed[col].apply(\n",
    "                        lambda x: self.label_encoders[col].transform([str(x)])[0] \n",
    "                        if str(x) in self.label_encoders[col].classes_ \n",
    "                        else most_frequent_encoded\n",
    "                    )\n",
    "        \n",
    "        # Step 7: Apply preprocessing\n",
    "        X_scaled = self.preprocessor.transform(X_processed)\n",
    "        \n",
    "        # Convert back to DataFrame\n",
    "        feature_names = self.numerical_cols + self.categorical_cols\n",
    "        X_scaled = pd.DataFrame(X_scaled, columns=feature_names)\n",
    "        \n",
    "        # Step 8: Make predictions (on transformed scale)\n",
    "        predictions_transformed = self.best_model.predict(X_scaled)\n",
    "        \n",
    "        # Step 9: Transform predictions back to original scale\n",
    "        predictions_original = self.inverse_transform_predictions(predictions_transformed)\n",
    "        \n",
    "        print(f\"Predictions completed for {len(predictions_original)} samples\")\n",
    "        \n",
    "        return predictions_original\n",
    "\n",
    "    def save_best_model(self, filepath='model/best_solar_model_complete.pkl'):\n",
    "        \"\"\"\n",
    "        Save the best model and all preprocessing components\n",
    "        \"\"\"\n",
    "        import pickle\n",
    "        import os\n",
    "        \n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        \n",
    "        model_package = {\n",
    "            'model': self.best_model,\n",
    "            'preprocessor': self.preprocessor,\n",
    "            'label_encoders': self.label_encoders,\n",
    "            'target_transformer': self.target_transformer,\n",
    "            'imputer': self.imputer,\n",
    "            'feature_names': self.feature_cols,\n",
    "            'categorical_cols': self.categorical_cols,\n",
    "            'numerical_cols': self.numerical_cols,\n",
    "            'best_model_name': self.best_model_name,\n",
    "            'best_score': self.best_score,\n",
    "            'features_to_drop': self.features_to_drop,\n",
    "            'best_results': self.best_results,\n",
    "            'target_col': self.target_col\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(model_package, f)\n",
    "        \n",
    "        print(f\"âœ… Best model with complete pipeline saved to {filepath}\")\n",
    "        print(f\"   Model: {self.best_model_name}\")\n",
    "        print(f\"   Score: {self.best_score:.4f}\")\n",
    "    \n",
    "    def load_model(self, filepath='model/best_solar_model_complete.pkl'):\n",
    "        \"\"\"\n",
    "        Load a saved model with complete pipeline\n",
    "        \"\"\"\n",
    "        import pickle\n",
    "        \n",
    "        with open(filepath, 'rb') as f:\n",
    "            model_package = pickle.load(f)\n",
    "        \n",
    "        self.best_model = model_package['model']\n",
    "        self.preprocessor = model_package['preprocessor']\n",
    "        self.label_encoders = model_package['label_encoders']\n",
    "        self.target_transformer = model_package['target_transformer']\n",
    "        self.imputer = model_package['imputer']\n",
    "        self.feature_cols = model_package['feature_names']\n",
    "        self.categorical_cols = model_package['categorical_cols']\n",
    "        self.numerical_cols = model_package['numerical_cols']\n",
    "        self.best_model_name = model_package.get('best_model_name', 'Unknown')\n",
    "        self.best_score = model_package.get('best_score', 0)\n",
    "        self.features_to_drop = model_package.get('features_to_drop', [])\n",
    "        self.best_results = model_package.get('best_results', {})\n",
    "        self.target_col = model_package.get('target_col', 'efficiency')\n",
    "        \n",
    "        print(f\"âœ… Model with complete pipeline loaded successfully\")\n",
    "        print(f\"   Model: {self.best_model_name}\")\n",
    "        print(f\"   Score: {self.best_score:.4f}\")\n",
    "        \n",
    "    def run_complete_pipeline(self):\n",
    "        \"\"\"\n",
    "        Run the complete model selection pipeline including stacking\n",
    "        \"\"\"\n",
    "        print(\"ðŸš€ STARTING COMPLETE SOLAR PANEL MODEL SELECTION PIPELINE\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Load and prepare data\n",
    "            print(\"\\nðŸ“Š STEP 1: Data Loading and Preparation\")\n",
    "            self.load_and_prepare_data()\n",
    "            \n",
    "            # Step 2: Create preprocessing pipeline\n",
    "            print(\"\\nðŸ”§ STEP 2: Creating Preprocessing Pipeline\")\n",
    "            self.create_preprocessing_pipeline()\n",
    "            \n",
    "            # Step 3: Prepare train-test split\n",
    "            print(\"\\nâœ‚ï¸ STEP 3: Train-Test Split\")\n",
    "            self.prepare_train_test_split()\n",
    "            \n",
    "            # Step 4: Define and evaluate base models\n",
    "            print(\"\\nðŸ¤– STEP 4: Base Model Evaluation\")\n",
    "            self.define_models()\n",
    "            self.evaluate_base_models()\n",
    "            \n",
    "            # Step 5: Hyperparameter tuning\n",
    "            print(\"\\nâš™ï¸ STEP 5: Hyperparameter Tuning\")\n",
    "            self.hyperparameter_tuning(top_n=5)\n",
    "            \n",
    "            # Step 6: Create stacking models\n",
    "            print(\"\\nðŸ—ï¸ STEP 6: Stacking Model Creation\")\n",
    "            self.create_stacking_models(n_best=2)\n",
    "            \n",
    "            # Step 7: Select best model\n",
    "            print(\"\\nðŸŽ¯ STEP 7: Best Model Selection\")\n",
    "            self.select_best_model()\n",
    "            \n",
    "            # Step 8: Print comprehensive results\n",
    "            print(\"\\nðŸ“Š STEP 8: Results Summary\")\n",
    "            self.print_results_summary()\n",
    "            \n",
    "            # Step 9: Save best model\n",
    "            print(\"\\nðŸ’¾ STEP 9: Saving Best Model\")\n",
    "            self.save_best_model()\n",
    "            \n",
    "            print(\"\\nðŸŽ‰ PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "            print(f\"ðŸ† Best Model: {self.best_model_name}\")\n",
    "            print(f\"ðŸ“ˆ Final Test Score: {self.best_score:.4f}\")\n",
    "            \n",
    "            return self.best_model, self.best_model_name, self.best_score\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ PIPELINE FAILED: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Usage example and main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸŒž SOLAR PANEL PERFORMANCE MODEL SELECTION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Define features to drop based on your analysis\n",
    "    features_to_drop = [\n",
    "        'soiling_loss',\n",
    "        'temp_difference', \n",
    "        'installation_type_tracking',\n",
    "        'pressure',\n",
    "        'wind_cooling_effect',\n",
    "        'id', 'voltage', 'current', 'temperature',\n",
    "        'module_temperature', 'irradiance', 'wind_speed',\n",
    "        'panel_age', 'cloud_coverage', \n",
    "        'soiling_ratio', 'maintenance_count', 'humidity'\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Initialize the model selector\n",
    "        print(\"ðŸ”§ Initializing model selector...\")\n",
    "        selector = SolarPanelModelSelector(\n",
    "            data_path='dataset/train.csv', \n",
    "            features_to_drop=features_to_drop,\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Run the complete pipeline\n",
    "        print(\"ðŸš€ Starting complete pipeline...\")\n",
    "        best_model, best_model_name, best_score = selector.run_complete_pipeline()\n",
    "        \n",
    "        print(f\"\\nðŸŽŠ FINAL RESULTS:\")\n",
    "        print(f\"   Best Model: {best_model_name}\")\n",
    "        print(f\"   Best Score: {best_score:.4f}\")\n",
    "        \n",
    "        # Example of making predictions on new data\n",
    "        print(f\"\\nðŸ“ USAGE EXAMPLES:\")\n",
    "        print(f\"   # Load new data and make predictions:\")\n",
    "        print(f\"   # new_data = pd.read_csv('new_data.csv')\")\n",
    "        print(f\"   # predictions = selector.predict(new_data)\")\n",
    "        print(f\"   \")\n",
    "        print(f\"   # Load saved model in new session:\")\n",
    "        print(f\"   # new_selector = SolarPanelModelSelector()\")\n",
    "        print(f\"   # new_selector.load_model('model/best_solar_model_complete.pkl')\")\n",
    "        print(f\"   # predictions = new_selector.predict(new_data)\")\n",
    "        \n",
    "        # Demonstrate model loading\n",
    "        print(f\"\\nðŸ”„ Testing model save/load functionality...\")\n",
    "        \n",
    "        # Save current model\n",
    "        selector.save_best_model('model/test_model.pkl')\n",
    "        \n",
    "        # Create new instance and load model\n",
    "        new_selector = SolarPanelModelSelector()\n",
    "        new_selector.load_model('model/test_model.pkl')\n",
    "        \n",
    "        print(f\"âœ… Model save/load test successful!\")\n",
    "        print(f\"   Loaded model: {new_selector.best_model_name}\")\n",
    "        print(f\"   Loaded score: {new_selector.best_score:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ ERROR: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    print(f\"\\nðŸ EXECUTION COMPLETED!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
